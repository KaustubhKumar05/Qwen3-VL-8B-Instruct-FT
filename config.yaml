# Vision LLM Benchmark Configuration

# List of models to test (OpenRouter models or Modal)
models_to_test:
  # - modal-hosted/fp8-prefix_caching  # modal-hosted Qwen3-VL-8B
  - qwen/qwen3-vl-8b-instruct
  - openai/gpt-4.1-mini
  - openai/gpt-5.2

# Model to use for generating ground truth (when regenerating ground truth files)
benchmark_model: openai/gpt-5.2

# Modal vLLM configuration
modal:
  timeout: 120  # Longer timeout for cold starts

# Ground truth regeneration behavior
ground_truth:
  replace_all: false  # If true, replace all existing. If false, only create for missing ones

prompt_file_name: base

# Directory containing benchmark sample images (used for prep, ground truth, and benchmarking)
active_dir: dataset

# Directory containing dataset images (for contamination check)
dataset_dir: dataset

# OpenRouter API configuration
openrouter:
  base_url: https://openrouter.ai/api/v1
  timeout: 60

# Scoring weights for different components
scoring_weights:
  base: 0.15
  wall: 0.15
  tall: 0.15
  loft: 0.15
  dado: 0.05
  floor: 0.05
  colors: 0.20
  handles: 0.10